---
title: "Data Analysis Master Thesis 2021"
author: "Pernille Berg Lassen"
date: "5/2/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---
Steps: 

1 Preliminary data exploration:

1.a Qualitity checks of the eye-tracking data
  How? Averaged across all participants? How to avoid a center-bias? (All data will be    clustered acround the center)
  
1.b Behavioral data
  Demographics: Age (mean, range, SD)
  General art-interest (between groups and across entire participant pool)
  Familiarity - how familiar were the artworks to the participants? Confounding?
  
  
2 Vizualitions (Both behavioral and eye-tracking data)
  Behavioral: Bar plots
  ET: Heat maps and scan paths
  
Scaling the ET data (viewing times are varied)


3 Defining AOI's/ROI's/Clusters
  Define AOI based on saliency maps (purely bottom-up) 
  Define clusters from the fixation data - dbscan (Davies et al.)
  Evt. define AOI based on Arnheim
  
4 Models
  4.a Behavioral data: (g)lmer
     Does condiiton predict ratings (understanding and appreciaiton)?
     Does rating predict artist/art-genre?
       Any artist/art-genre that recieved hihger/lower ratings?
     Does art interest predict ratings? A trend across artist/art-genre?
     Does familiarity (if relevant - depends on the overall familiarity level)?
     
  Check correlation between the questions - collapse or nah?
  
  4.b ET: glmer
    NB: a sequential dimensions - first five fixations (more bottom-up) vs. the rest        (more top-down)
    Does duration of fixation + number of fixations predict condition? (Or the other way     around)?
    Does time spent in AOI predict condition? (or the other way around)?
    Does time to first fixation in AOI's predict condition? (or the other way around)?
    Does total viewing time (scaled) predict condition/artist/art-genre? 
    
5 Saliency algoritm
  ET: looking at the effect of saliency
  NB: The whole dataset (averaged across participants) vs. fixations only in   clusters   (so AOI defined from the fixations)?)
  
  First five fixations vs. the rest of the fixations. 
  
  ROC and AUC - accuracy
  
  Saliency maps + three conspicuity maps (color, intensity and orientation)
  
6 Model evaluation
  Cross-validation of models - investigate predictive power as well as explanatory
  
Transition behavior between clusters?

###Loading packages
```{r}
library(pacman)
p_load(devtools,tidyverse,lmerTest,data.table,ggpubr,caret,lme4,png,dbscan,gtools)
library(factoextra)
#library(edfReader)
```


```{r}
#Load data
BehaveDat = read.csv("DataBsC/BehavioralData_New.csv") #<-- using data from the Bachelor to test code
BehaveDat = subset(BehaveDat, select = -c(X))

SacDat = read.csv("DataBsc/SaccadesData_New.csv",header = T)
SacDat = subset(SacDat, select = -c(X))
SacDat = subset(SacDat, select = -c(Number_sac))
SacDat = subset(SacDat,SacDat$Duration < 80) #Removing artifacts

FixDat = read.csv("DataBsC/FixationsData_New.csv", header = T)
FixDat = subset(FixDat, select = -c(X))
FixDat = subset(FixDat, select = -c(Number_fix))
FixDat = subset(FixDat,FixDat$Duration > 200) #Removing artifacts

count = group_by(FixDat,image,ID) %>% summarize(Number_fix=n())
countSac = group_by(SacDat,image,ID) %>% summarize(Number_sac=n())
Fix_df = plyr::join(FixDat,count)
Sac_df = plyr::join(SacDat,countSac)
Fix_df$PositionY = round((901-Fix_df$PositionY),2) #Data was flipped

#remove(FixDat)
#remove(SacDat)
#remove(count)
#remove(countSac)

#Including only five first fixations on each image
Fix_df_small <-
Fix_df %>% 
  group_by(ID,image) %>% 
  filter(row_number()==1:5)

#Including only first five seconds
temp_df <- subset(Fix_df, select = c(ID, image, sttime, entime))

temp_df <- temp_df %>%
  group_by(image,ID) %>% 
  summarise(trial_stattime = sttime[1])

temp_df <- merge(Fix_df,temp_df)

temp_df$time_passed <- temp_df$entime - temp_df$trial_stattime
temp_df$time_passed <- temp_df$time_passed/1000 #In seconds

Fix_df_fiveS <- subset(temp_df, temp_df$time_passed <= 5)

Fix_df_fiveS$image = str_replace_all(Fix_df_fiveS$image,"images_",'')
Fix_df_fiveS$image = str_replace_all(Fix_df_fiveS$image,"\\\\fig",'')
Fix_df_fiveS$image = str_replace_all(Fix_df_fiveS$image,"\\\\abstract",'')
Fix_df_fiveS$image = str_replace_all(Fix_df_fiveS$image,".png",'')
Fix_df_fiveS$image = str_replace_all(Fix_df_fiveS$image, 'pollock_1', 'pollock_')
Fix_df_fiveS$image = str_replace_all(Fix_df_fiveS$image, 'pollock_20','pollock_10')
Fix_df_fiveS$image = str_replace_all(Fix_df_fiveS$image, 'schiele_1', 'schiele_')
Fix_df_fiveS$image = str_replace_all(Fix_df_fiveS$image, 'schiele_20','schiele_10')


#Recap:
#Fix_df = full dataset
#Fix_df_fiveS = first five seconds only
#Fix_df_small = first five fixations only
```

Vizualizations

```{r}
#Demographics

Dat_grouped = group_by(BehaveDat,ID,gender,condition,age) %>% summarize()

sum(Dat_grouped$gender == 'Female' & Dat_grouped$condition == 1) 
sum(Dat_grouped$gender == 'Female' & Dat_grouped$condition == 0) 
sum(Dat_grouped$gender == 'Male' & Dat_grouped$condition == 1) 
sum(Dat_grouped$gender == 'Male' & Dat_grouped$condition == 0)
round(mean(Dat_grouped$age),2)
round(sd(Dat_grouped$age),2)
round(mean(Dat_grouped$age[Dat_grouped$condition == 1]),2)
round(sd(Dat_grouped$age[Dat_grouped$condition == 1]),2)
round(mean(Dat_grouped$age[Dat_grouped$condition == 0]),2)
round(sd(Dat_grouped$age[Dat_grouped$condition == 0]),2)

#Image familarity 

Image_grouped = group_by(BehaveDat, ID, image, q7, artist, genre) %>% summarize()
img_fam = subset(Image_grouped,Image_grouped$q7 == 'yes')
img_fam = group_by(img_fam,image, artist, genre)  %>% summarize(Number_yes=n())
img_fam$Number_yes = sort(img_fam$Number_yes, decreasing = T)

summary(img_fam$artist) 
summary(img_fam$genre)

sum(img_fam$Number_yes[img_fam$artist == 'chagall']) #change with relevant artist names
sum(img_fam$Number_yes[img_fam$artist == 'schiele'])
sum(img_fam$Number_yes[img_fam$artist == 'rothko'])
sum(img_fam$Number_yes[img_fam$artist == 'pollock'])

sum(img_fam$Number_yes[img_fam$genre == 'fig'])
sum(img_fam$Number_yes[img_fam$genre == 'abstract'])


#Art interest
art_interest <- BehaveDat %>% #summarizing results from art interest questionaire
  group_by(ID) %>%
  summarize(
    q8 = q8[1],
    q9 = q9[1],
    q10 = q10[1],
    q11 = q11[1],
    condition = condition[1]
  )

#How many participants have taken art-classes?

length(art_interest$ID[art_interest$q11 == "yes" & art_interest$condition == 1])
length(art_interest$ID[art_interest$q11 == "yes" & art_interest$condition == 0])

art_interest$condition = as.factor(art_interest$condition)

art_interest$condition = plyr::revalue(art_interest$condition, c("1"= "Experts", "0"= "Non-Experts"))

all_part <- ggplot(art_interest, aes(x = q8)) +
  geom_bar(fill = "#99CCFF") +
  xlab("Ratings: Question X") +
  ylab("Participant counts") +
  theme_minimal()
  #How to change the values on the y-axis?

#Bar plots
bar_plot <- ggplot(art_interest, aes(x = q8)) + 
  geom_bar(fill = "#99CCFF") + 
  facet_wrap(~condition) + 
  xlab("Ratings: Question X") + 
  ylab("Partcipant counts") + 
  theme_minimal()

box_plot <- ggplot(art_interest,aes(y=q9,x=condition)) +
  geom_boxplot(color = "#336699", fill = "#6699CC") +
  xlab("Condition") +
  ylab("Rating") +
  ggtitle("Question X") + 
  coord_cartesian(ylim = c(1, 7)) +
  theme_minimal()

#Leaving an axis label blank: theme(axis.title.y = element_blank())

ggarrange(all_part,bar_plot) #what plots to display next to one another?

```

Testing art-interest

```{r}
#Mean and SD
art_interest %>%
  group_by(condition) %>%
  summarize(
    mean_q8 = round(mean(q8),2),
    sd_q8 = round(sd(q8),2),
    mean_q9 = round(mean(q9),2),
    sd_q9 = round(sd(q9),2),
    mean_q10 = round(mean(q10),2),
    sd_q10 = round(sd(q10),2)
  )

#testing assumptions - what to test?

model <- glm(condition ~ q8, family = 'binomial', art_interest) #one model per question or one model with all questions?
summary(model)


```

Scanpaths and heatmaps

```{r}
#Acessing quality of ET data?
#Subsetting dataframe to make heatmaps for 4 chosen images

img <- png::readPNG('DataBsC/heatmaps_scanpaths_images/screenshot_fig11.png')
g <- grid::rasterGrob(img, interpolate = T)

jet.colors <- colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan", "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"))

#Participant 1
heatmap_P1 <- ggplot(subset(Fix_df, ID==1 & image=='images_schiele\\fig_11.png'),aes(x = PositionX, y = PositionY)) +
  xlim(0,1600) +
  ylim(0, 900) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=900) +
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) +
scale_alpha(range = c(0.1, 0.6)) + scale_fill_gradientn(colours = jet.colors(10), trans='sqrt')

#Participant 2
heatmap_P2 <- ggplot(subset(Fix_df, ID==2 & image=='images_rothko\\abstract_6.png'),aes(x = PositionX, y = PositionY)) +
  xlim(0,1600) +
  ylim(0, 900) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=900) +
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) +
scale_alpha(range = c(0.1, 0.6)) + scale_fill_gradientn(colours = jet.colors(10), trans='sqrt')

#All participants
heatmap <- ggplot(subset(Fix_df, image=='images_schiele\\fig_11.png'),aes(x = PositionX, y = PositionY)) +
  xlim(0,1600) +
  ylim(0, 900) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=900) +
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) +
scale_alpha(range = c(0.1, 0.6)) + scale_fill_gradientn(colours = jet.colors(10), trans='sqrt')

averaged_heatmaps <- Fix_df %>%
  group_by(image) %>%
  mutate(Counter = sequence(rle(ID)$lengths)) %>%
  ungroup() %>%
  group_by(image, Counter) %>%
  summarize(
    PositionX = median(PositionX),
    PositionY = median(PositionY)
  )

aveHM <-
  ggplot(subset(averaged_heatmaps,image == "images_schiele\\fig_11.png"),aes(x =1601-PositionX, y = PositionY)) +
  xlim(0,1600) +
  ylim(0,900) +
  annotation_custom(g,xmin=-Inf, xmax=Inf, ymin=-0, ymax=900) +
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) + scale_alpha(range = c(0.1, 0.6)) +
  scale_fill_gradientn(colours = jet.colors(10), trans='sqrt') + ggtitle("All Participants")

#Remove fixations that is not on the stimulus?

```

Cluster definition using DBSCAN

```{r}
#Testing dbscan

test <- subset(averaged_heatmaps, averaged_heatmaps$image == 'images_pollock\\abstract_17.png') #average fixations for one image

test <- subset(test, select = c(PositionX,PositionY)) #selecting fixations position only
test <- as.matrix(test) #dbscan works with matrices
kNNdistplot(test,k=4) + abline(h = 60, col = "red", lty = 2) #use knn distance plot to determine optimal eps value - look for where the data changes significantly (from linear to exponential)
db <- dbscan(test, eps = 40) #run cluster analysis

bkg_img <- png::readPNG("DataBsC/heatmaps_scanpaths_images/screenshot_fig1.png")
pairs(test, col = db$cluster + 1L) #clusters seperated by axis
plot(test, col = db$cluster + 1L) #clusters = red, noise points = black
limits <- par() 
rasterImage(bkg_img, limits$usr[1], limits$usr[3], limits$usr[2], limits$usr[4]) 
points(test[db$cluster==0,], pch = 3, col = "grey")

img <- png::readPNG('DataBsC/heatmaps_scanpaths_images/screenshot_abs17.png')
g <- grid::rasterGrob(img, interpolate = T)

test <- as.data.frame(test)

plot_2 <- ggplot(test, aes(x = PositionX, y = PositionY)) +
  xlim(0,1600) +
  ylim(0,900) +
  annotation_custom(g, xmin=-0, xmax=1600, ymin=-0, ymax=900) +
  geom_point()

#Prettier visualization - How to add a background image?
plot  <-  fviz_cluster(db, test, stand = FALSE, geom = "point", main = "Cluster formation in 'Number 8' by Jackson Pollock") +
  xlim(0,1600) +
  ylim(0,900)
```

Sparseness and saliency maps
```{r}
#Playing around with sparseness

#Prepping a dataframe
sparseness_resized_df <- data.frame(ID = numeric(),
                            L1 = numeric(),
                            L2 = numeric(),
                            median_sal = numeric(),
                            mean_sal = numeric(),
                            sparseness = numeric())


temp = list.files(path = "salmaps/Resized/", pattern="*.csv", full.names = T)
new_temp <- mixedsort(temp)
myfiles = lapply(new_temp,read.delim,sep=",",header = F)

#Resized is the saliency maps fit to the orignal size of the image - large files, takes a little to load

N_resized = 1440000 #number of pixels in resized images/maps
N = 576 #number of pixels in conspicuity maps and 'actual' saliency maps

#Equation for calculating sparseness is adapted from Koide et al. (2015)

ID = 1
for (map in myfiles){
  L1 <- sum(map)
  L2 <- sqrt(sum(map^2))
  median_sal_val <- median(as.matrix(map))
  mean_sal_val <- mean(as.matrix(map))
  sparseness_val <- (1/(sqrt(N_resized)-1))*(sqrt(N_resized)-(L1/L2))
  sparseness_resized_df[nrow(sparseness_resized_df) + 1,] = c(ID = ID, L1 = L1, L2 = L2, median_sal = median_sal_val, mean_sal = mean_sal_val, sparseness = sparseness_val)
  ID = ID + 1
}

sparseness_resized_df$artist <- c(rep("Chagall", 10), rep("Pollock", 10),
                                  rep("Rothko", 10), rep("Schiele", 10))

#Conspicuity and 'acutal' maps

temp = list.files(path = "salmaps/Conspicuity maps/", pattern="*_ori.csv", full.names = T)
new_temp <- mixedsort(temp) #make sure they are sorted before adding ID coloumn/artist

myfiles = lapply(new_temp,read.delim,sep=",",header = F)

sparseness_ori_df <- data.frame(ID = numeric(),
                            L1 = numeric(),
                            L2 = numeric(),
                            median_sal = numeric(),
                            mean_sal = numeric(),
                            sparseness = numeric())

ID = 1
for (map in myfiles){
  L1 <- sum(map)
  L2 <- sqrt(sum(map^2))
  median_sal_val <- median(as.matrix(map))
  mean_sal_val <- mean(as.matrix(map))
  sparseness_val <- (1/(sqrt(N)-1))*(sqrt(N)-(L1/L2))
  sparseness_color_df[nrow(sparseness_color_df) + 1,] = c(ID = ID, L1 = L1, L2 = L2, median_sal = median_sal_val, mean_sal = mean_sal_val, sparseness = sparseness_val)
  ID = ID + 1
}

sparseness_ori_df$Image <- c(rep(seq(1:10), 4))
sparseness_ori_df$Image <- paste(sparseness_ori_df$artist,"_",sparseness_ori_df$Image)
sparseness_ori_df$Image <- gsub( " ", "", sparseness_ori_df$Image) 

#cols.num <- c("L1","L2","median_sal","mean_sal","sparseness") - if non-numeric
#sparseness_df[cols.num] <- sapply(sparseness_df[cols.num],as.numeric)
#Checking classes of variables: sapply(sparseness_df, class)

#sparseness_df %>% mutate_at(vars(L1, L2,median_sal,mean_sal,sparseness), funs(round(., 2)))

median(sparseness_df$sparseness) #0.4297284
median(sparseness_resized_df$sparseness) #0.4114786
median(sparseness_color_df$sparseness) #0.4373788
median(sparseness_int_df$sparseness) #0.4275935
median(sparseness_ori_df$sparseness) #0.4139771

sparseness_df$Image[sparseness_df$sparseness >= 0.4297284] 
sparseness_color_df$Image[sparseness_color_df$sparseness >= 0.4373788]
sparseness_int_df$Image[sparseness_int_df$sparseness >= 0.4275935]
sparseness_ori_df$Image[sparseness_ori_df$sparseness >= 0.4139771]
#Some slight differences in classification between maps

few_peak <- subset(sparseness_df,sparseness_df$sparseness >= 0.4297284)
few_peak$peak_group <- 'few'
many_peak <- subset(sparseness_df,sparseness_df$sparseness < 0.4297284)
many_peak$peak_group <- 'many'

peak <- rbind(few_peak,many_peak)
peak <- subset(peak, select = -c(ID,artist))
peak$Image = tolower(peak$Image)
colnames(peak)[6] <- "image"

Fix_df_fiveS <- merge(Fix_df_fiveS,peak)

#Which value to properly display the many_peak/few_peak?

```


```{r}
#Prepping data for matlab

averaged_dataC0 <- subset(Fix_df_fiveS, condition == 0) %>%
  group_by(image) %>%
  mutate(Counter = sequence(rle(ID)$lengths)) %>%
  ungroup() %>%
  group_by(image, Counter) %>%
  summarize(
    PositionX = median(PositionX),
    PositionY = median(PositionY),
    Condition = condition[1]
  )

averaged_dataC1 <- subset(Fix_df_fiveS, condition == 1) %>%
  group_by(image) %>%
  mutate(Counter = sequence(rle(ID)$lengths)) %>%
  ungroup() %>%
  group_by(image, Counter) %>%
  summarize(
    PositionX = median(PositionX),
    PositionY = median(PositionY),
    Condition = condition[1]
  )

testC1 = subset(averaged_dataC1, image == "schiele_1")
testC0 = subset(averaged_dataC0, image == "schiele_1")
testC1 = subset(testC1, select = c(PositionX, PositionY))
testC0 <- subset(testC0, select = c(PositionX, PositionY))

write.csv(testC1,"fig_11_C1_firstF.csv")
write.csv(testC0,"fig_11_C0_firstF.csv")

Score_fig_1_C1 = 0.899040274445397
Score_fig_1_C0 = 0.937433046642523

Score_fig_11_C1 = 0.956673044003625
Score_fig_11_C0 = 0.945405852103653

Score_abs_11_C1 = 0.765185781895076
Score_abs_11_C0 = 0.787589818020201

Score_abs_4_C1 = 0.943451539762291
Score_abs_4_C0 = 0.961157295685055

AUC_df_C0 <- data.frame(Genre = c(rep("abs",2),rep("fig",2)), Condition = rep(0, 4), AUC = c(0.961157295685055,0.787589818020201,0.937433046642523,0.945405852103653))

AUC_df_C1 <-  data.frame(Genre = c(rep("abs",2),rep("fig",2)), Condition = rep(1, 4), AUC = c(0.943451539762291, 0.765185781895076, 0.899040274445397, 0.956673044003625))

AUC_df = rbind(AUC_df_C0,AUC_df_C1)

t.test(AUC_df_C0$AUC,AUC_df_C1$AUC)

mean(AUC_df_C0$AUC)
mean(AUC_df_C1$AUC)

```

